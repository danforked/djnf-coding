{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's scrape the IRE homepage\n",
    "\n",
    "Our goal: Print out the headlines from the [IRE home page](https://ire.org/).\n",
    "\n",
    "[`requests`](http://docs.python-requests.org/en/master/) is a handy third-party library for making HTTP requests. It does the same thing your browser does when you type in a URL and hit enter -- sends a message to a server and requests a copy of the page -- but it allows us to do this programatically instead of pointing and clicking. For our purposes today, we're interested in the library's [`get()`](http://docs.python-requests.org/en/master/api/#requests.get) method.\n",
    "\n",
    "We'll use the [BeautifulSoup library](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), aka `bs4`, to parse the HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and parse the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the `get()` method to fetch a copy of the IRE home page\n",
    "ire_page = requests.get('http://ire.org')\n",
    "\n",
    "# feed the text of the web page to a BeautifulSoup object\n",
    "soup = BeautifulSoup(ire_page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target the headlines\n",
    "\n",
    "View source on the IRE homepage and find the headlines. What's the pattern?\n",
    "\n",
    "We'll use the [`find_all()`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree) method to get all of the headlines (`h1`) withe the class `title1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of headlines we're interested in\n",
    "heds = soup.find_all('h1', {'class': 'title1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over the heds, printing out the text\n",
    "\n",
    "You can drill down into a nested tag using a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digital Crime Correspondent  (Major Network)\n",
      "City Editor (The Press Democrat)\n",
      "Digital Editor (FRONTLINE)\n",
      "Professor (University of Maryland)\n",
      "Russiagate Freelance Reporter (WhoWhatWhy)\n",
      "Investigative Reporter (Talking Points Memo)\n",
      "Finalists announced for 2018 Golden Padlock Award\n"
     ]
    }
   ],
   "source": [
    "for hed in heds:\n",
    "    print(hed.a.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ‘‰ For more details on using _for_ loops, [see this notebook](../../reference/Python%20data%20types%20and%20basic%20syntax.ipynb#for-loops)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
